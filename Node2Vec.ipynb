{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node2Vec:\n",
    "    def __init__(self, g, p=1, q=1, num_walks=10, walk_length=10, dimensions=300,\n",
    "                 window_size=10, workers=8, iterations=1, output=None):\n",
    "        self.G = g\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.num_walks = num_walks\n",
    "        self.walk_length = walk_length\n",
    "        self.dimensions = dimensions\n",
    "        self.window_size = window_size\n",
    "        self.workers = workers\n",
    "        self.iterations = iterations\n",
    "        self.output = output\n",
    "        self.alias_nodes = dict()\n",
    "        self.alias_edges = dict()\n",
    "\n",
    "    def __alias_setup__(self, probs):\n",
    "        K = len(probs)\n",
    "        q = np.zeros(K)\n",
    "        J = np.zeros(K, dtype=np.int)\n",
    "        smaller = []\n",
    "        larger = []\n",
    "        for kk, prob in enumerate(probs):\n",
    "            q[kk] = K * prob\n",
    "            if q[kk] < 1.0:\n",
    "                smaller.append(kk)\n",
    "            else:\n",
    "                larger.append(kk)\n",
    "        while len(smaller) > 0 and len(larger) > 0:\n",
    "            small = smaller.pop()\n",
    "            large = larger.pop()\n",
    "            J[small] = large\n",
    "            q[large] = q[large] + q[small] - 1.0\n",
    "            if q[large] < 1.0:\n",
    "                smaller.append(large)\n",
    "            else:\n",
    "                larger.append(large)\n",
    "        return J, q\n",
    "\n",
    "    def __get_alias_edge__(self, src, dst):\n",
    "        unnormalized_probs = []\n",
    "        for dst_nbr in sorted(self.G.neighbors(dst)):\n",
    "            if dst_nbr == src:\n",
    "                unnormalized_probs.append(self.G[dst][dst_nbr]['weight'] / self.p)\n",
    "            elif self.G.has_edge(dst_nbr, src):\n",
    "                unnormalized_probs.append(self.G[dst][dst_nbr]['weight'])\n",
    "            else:\n",
    "                unnormalized_probs.append(self.G[dst][dst_nbr]['weight'] / self.q)\n",
    "        norm_const = sum(unnormalized_probs)\n",
    "        normalized_probs = [float(u_prob) / norm_const for u_prob in unnormalized_probs]\n",
    "\n",
    "        return self.__alias_setup__(normalized_probs)\n",
    "\n",
    "    def __alias_draw__(self, J, q):\n",
    "        K = len(J)\n",
    "\n",
    "        kk = int(np.floor(np.random.rand() * K))\n",
    "        if np.random.rand() < q[kk]:\n",
    "            return kk\n",
    "        else:\n",
    "            return J[kk]\n",
    "\n",
    "    def __node2vec_walk__(self, start_node):\n",
    "        walk = [start_node]\n",
    "        while len(walk) < self.walk_length:\n",
    "            cur = walk[-1]\n",
    "            cur_nbrs = sorted(self.G.neighbors(cur))\n",
    "            if len(cur_nbrs) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(cur_nbrs[self.__alias_draw__(self.alias_nodes[cur][0], self.alias_nodes[cur][1])])\n",
    "                else:\n",
    "                    prev = walk[-2]\n",
    "                    nxt = cur_nbrs[self.__alias_draw__(self.alias_edges[(prev, cur)][0], self.alias_edges[(prev, cur)][1])]\n",
    "                    walk.append(nxt)\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    def preprocess_transition_probs(self):\n",
    "        for node in self.G.nodes():\n",
    "            unnormalized_probs = [self.G[node][nbr]['weight'] for nbr in sorted(self.G.neighbors(node))]\n",
    "            norm_const = sum(unnormalized_probs)\n",
    "            normalized_probs = [float(u_prob) / norm_const for u_prob in unnormalized_probs]\n",
    "            self.alias_nodes[node] = self.__alias_setup__(normalized_probs)\n",
    "\n",
    "        for edge in self.G.edges():\n",
    "            self.alias_edges[edge] = self.__get_alias_edge__(edge[0], edge[1])\n",
    "            # self.alias_edges[(edge[1], edge[0])] = self.__get_alias_edge__(edge[1], edge[0])\n",
    "        return\n",
    "\n",
    "    def simulate_walks(self):\n",
    "        walks = []\n",
    "        nodes = list(self.G.nodes())\n",
    "        print('Walk iteration:')\n",
    "        for walk_iter in range(self.num_walks):\n",
    "            print(walk_iter + 1, ' out of ', self.num_walks)\n",
    "            random.shuffle(nodes)\n",
    "            for node in nodes:\n",
    "                walks.append(self.__node2vec_walk__(start_node=node))\n",
    "        return walks\n",
    "\n",
    "    def learn_embeddings(self, walks):\n",
    "        model = Word2Vec(walks, size=self.dimensions, window=self.window_size,\n",
    "                         min_count=0, sg=1, workers=self.workers, iter=self.iterations)\n",
    "        model.wv.save_word2vec_format(self.output)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(file_name):\n",
    "    g = nx.read_gpickle(file_name)\n",
    "    for edge in g.edges():\n",
    "        g[edge[0]][edge[1]]['weight'] = 1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Add the input and output files here in the same sequence.\n",
    "    input_file = ['data/references_network_2hops_wos.gpickle', 'data/citations_network_2hops_mag.gpickle',\n",
    "                  'data/references_network_2hops_mag.gpickle']\n",
    "    output_file = ['data/node2vec_references_network_2hops_wos.emb', 'data/node2vec_citations_network_2hops_mag.emb',\n",
    "                   'data/node2vec_references_network_2hops_mag.emb']\n",
    "    for i in range(len(input_file)):\n",
    "        print('----------Getting Features for file ', i + 1, '----------')\n",
    "        nx_G = read_graph(input_file[i])\n",
    "        n2v = Node2Vec(nx_G, p=2, q=2, output=output_file[i])\n",
    "        print('----Preprocessing----')\n",
    "        n2v.preprocess_transition_probs()\n",
    "        print('----Generate Random Walks----')\n",
    "        rand_walk = n2v.simulate_walks()\n",
    "        print('----Word2Vec----')\n",
    "        n2v.learn_embeddings(rand_walk)\n",
    "        print('--Completed--')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
