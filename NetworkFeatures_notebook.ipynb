{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NetworkGraph:\n",
    "    def __init__(self):\n",
    "        self.path_head = '../DataExtraction/WOS/RPPdataConverted'\n",
    "        self.df = None\n",
    "\n",
    "    def get_data(self, features=['DOI', 'Study.Title.O']):\n",
    "        if features == 'all':\n",
    "            self.df = pd.read_excel('data/new_data.xlsx', encoding='ansi',)\n",
    "        else:\n",
    "            self.df = pd.read_excel('data/new_data.xlsx', encoding='ansi', usecols=features)\n",
    "\n",
    "    def citation_graph(self):\n",
    "        g = nx.Graph()\n",
    "        nodes = dict()\n",
    "        self.df.dropna(subset=['DOI'])\n",
    "        for idx, row in self.df.iterrows():\n",
    "            print('Row id: ', idx)\n",
    "            name = row['DOI'].replace('/', '_')\n",
    "            file_name = self.path_head + '/{}/citations_{}.txt'.format(name, name)\n",
    "            if os.path.exists(file_name):\n",
    "                if name not in nodes and row['Study.Title.O'] not in nodes.values():\n",
    "                    g.add_node(name)\n",
    "                    nodes[name] = row['Study.Title.O']\n",
    "                elif row['Study.Title.O'] in nodes.values():\n",
    "                    del nodes[row('Study.Title.O')]\n",
    "                    nodes[name] = row['Study.Title.O']\n",
    "                    g.remove_node(row('Study.Title.O'))\n",
    "                    g.add_node(name)\n",
    "                df_doi = pd.read_csv(file_name, sep='\\t', lineterminator='\\r', encoding=\"utf-16le\",\n",
    "                                     index_col=False, quotechar=None, quoting=3, usecols=['DI', 'TI'])\n",
    "                df_doi = df_doi.dropna()\n",
    "                for i, citation_row in df_doi.iterrows():\n",
    "                    if citation_row['DI']:\n",
    "                        if citation_row['DI'] not in nodes and citation_row['TI'] not in nodes:\n",
    "                            g.add_node(citation_row['DI'])\n",
    "                            nodes[citation_row['DI']] = citation_row['TI']\n",
    "                        elif citation_row['TI'] in nodes:\n",
    "                            del nodes[citation_row['TI']]\n",
    "                            nodes[citation_row['DI']] = citation_row['TI']\n",
    "                            g.remove_node(citation_row['TI'])\n",
    "                            g.add_node(citation_row['DI'])\n",
    "                            g.remove_edge(citation_row['TI'], name)\n",
    "                        g.add_edge(name, citation_row['DI'])\n",
    "                    elif citation_row['TI']:\n",
    "                        if citation_row['TI'] not in nodes:\n",
    "                            g.add_node(citation_row['TI'])\n",
    "                            nodes[citation_row['TI']] = citation_row['TI']\n",
    "                        g.add_edge(name, citation_row['TI'])\n",
    "        print('-------------Saving Graph--------------')\n",
    "        print('Number of nodes in the graph: ', len(g.nodes()))\n",
    "        print('Number of edges in the graph: ', len(g.edges()))\n",
    "        nx.write_gpickle(g, 'data/citations_network.gpickle')\n",
    "        nx.write_gexf(g, \"data/citations_network.gexf\")\n",
    "        print('-------------Graph Saved--------------')\n",
    "\n",
    "    def coauthorship_graph(self):\n",
    "        g = nx.Graph()\n",
    "        nodes = set()\n",
    "        self.df.dropna(subset=['DOI'])\n",
    "        for idx, row in self.df.iterrows():\n",
    "            print('Row id: ', idx)\n",
    "            name = row['DOI'].replace('/', '_')\n",
    "            folder_name = self.path_head + '/{}/'.format(name)\n",
    "            if os.path.exists(folder_name):\n",
    "                for file_name in os.listdir(folder_name):\n",
    "                    if file_name.startswith(\"authors_\"):\n",
    "                        df_doi = pd.read_csv(folder_name + '/' + file_name, sep='\\t', lineterminator='\\r', encoding=\"utf-16le\",\n",
    "                                             index_col=False, quotechar=None, quoting=3, usecols=['AU'])\n",
    "                        df_doi.dropna()\n",
    "                        co_authors = dict()\n",
    "                        for _, authors_row in df_doi.iterrows():\n",
    "                            cur_auths = authors_row['AU'].split(';')\n",
    "                            cur_auths = [x.strip().lower() for x in cur_auths]\n",
    "                            for au in cur_auths:\n",
    "                                if au in co_authors:\n",
    "                                    co_authors[au] += 1\n",
    "                                else:\n",
    "                                    co_authors[au] = 1\n",
    "                        main_author = max(co_authors, key=co_authors.get)\n",
    "                        if main_author not in nodes:\n",
    "                            g.add_node(main_author)\n",
    "                            nodes.add(main_author)\n",
    "                        for _, authors_row in df_doi.iterrows():\n",
    "                            cur_auths = authors_row['AU'].split(';')\n",
    "                            cur_auths = [x.strip().lower() for x in cur_auths]\n",
    "                            for au in cur_auths:\n",
    "                                if au not in nodes:\n",
    "                                    nodes.add(au)\n",
    "                                if main_author != au:\n",
    "                                    g.add_edge(main_author, au)\n",
    "                            for au_comb in itertools.combinations(cur_auths, 2):\n",
    "                                if au not in nodes:\n",
    "                                    nodes.add(au)\n",
    "                                if main_author != au:\n",
    "                                    g.add_edge(au_comb[0], au_comb[1])\n",
    "        print('-------------Saving Graph--------------')\n",
    "        print('Number of nodes in the graph: ', len(g.nodes()))\n",
    "        print('Number of edges in the graph: ', len(g.edges()))\n",
    "        nx.write_gpickle(g, 'data/coauthorship_network.gpickle')\n",
    "        nx.write_gexf(g, \"data/coauthorship_network.gexf\")\n",
    "        print('-------------Graph Saved--------------')\n",
    "\n",
    "    def display_graph(self, file):\n",
    "        print('-------------Generating Graph----------')\n",
    "        g = nx.read_gpickle(file)\n",
    "        print('Number of nodes in the graph: ', len(g.nodes()))\n",
    "        print('Number of edges in the graph: ', len(g.edges()))\n",
    "        nx.draw_networkx(G=g, pos=nx.spring_layout(g), node_color='r', alpha=0.8,\n",
    "                         node_size=[g.degree(n) * 3 for n in g.nodes()], with_labels=False)\n",
    "        plt.show()\n",
    "\n",
    "    def addNetworkFeatures(self):\n",
    "        with open('data/node2vec_citations.emb', 'r') as f_read:\n",
    "            lines = f_read.readlines()\n",
    "            for row in range(len(lines)):\n",
    "                if row > 0:\n",
    "                    vals = lines[row].split(' ')\n",
    "                    doi = vals[0]\n",
    "                    # Check for Titles instead of DOIS too\n",
    "                    if doi[0] == '1':\n",
    "                        doi = doi.replace('_', '/')\n",
    "                        print('--------------------DOI: ', doi, ' and row: ', row + 1, '--------------------')\n",
    "                        for idx in range(len(vals) - 1):\n",
    "                            self.df.loc[self.df['DOI'] == doi, 'new_feature_' + str(idx + 1)] = vals[idx + 1]\n",
    "        self.df.to_excel('data/final_network_data.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    cnn = NetworkGraph()\n",
    "    # Uncomment below to generate the graph: Step-2\n",
    "    # cnn.get_data()\n",
    "    # cnn.citation_graph()\n",
    "    # cnn.coauthorship_graph()\n",
    "    \n",
    "    # Uncomment below to add the generated node2vec features to our data: Step-4\n",
    "    cnn.get_data('all')\n",
    "    cnn.addNetworkFeatures()\n",
    "    \n",
    "    # Uncomment below to display the generated graph\n",
    "    # cnn.display_graph('data/citations_network.gpickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
