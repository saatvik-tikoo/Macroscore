{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas\n",
    "from sklearn import ensemble\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import sklearn.metrics as mx\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X_train, X_test, y_train, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return mx.accuracy_score(y_test, y_pred)\n",
    "\n",
    "def ablation_test(df, label_type):\n",
    "    df = remove_unusable_features(df, label_type)\n",
    "    X = df.drop([label_type], axis=1)\n",
    "    y = df[label_type]\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    svc = SVC(kernel='rbf', gamma=1, C=0.1, random_state=0)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=6, p=2, weights='uniform')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    base_score = dict()\n",
    "    base_score['gnb'] = self.__score_model__(X_train, X_test, y_train, y_test, gnb)\n",
    "    base_score['svc'] = self.__score_model__(X_train, X_test, y_train, y_test, svc)\n",
    "    base_score['neigh'] = self.__score_model__(X_train, X_test, y_train, y_test, neigh)\n",
    "\n",
    "    scores = defaultdict(list)\n",
    "    for i in range(X_train.shape[1]):\n",
    "        cols = [ndx != i for ndx in range(X_train.shape[1])]\n",
    "        scores['gnb'].append(self.__score_model__(X_train.iloc[:, cols], X_test.iloc[:, cols], y_train, y_test, gnb))\n",
    "        scores['svc'].append(self.__score_model__(X_train.iloc[:, cols], X_test.iloc[:, cols], y_train, y_test, svc))\n",
    "        scores['neigh'].append(self.__score_model__(X_train.iloc[:, cols], X_test.iloc[:, cols], y_train, y_test, neigh))\n",
    "\n",
    "    final_scores_gnb = dict()\n",
    "    final_scores_svc = dict()\n",
    "    final_scores_neigh = dict()\n",
    "    for k, v in scores.items():\n",
    "        if k == 'gnb':\n",
    "            for i in range(len(v)):\n",
    "                final_scores_gnb[X.columns[i]] = (v[i] - base_score[k])\n",
    "            final_scores_gnb = sorted(final_scores_gnb.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        elif k == 'svc':\n",
    "            for i in range(len(v)):\n",
    "                final_scores_svc[X.columns[i]] = (v[i] - base_score[k])\n",
    "            final_scores_svc = sorted(final_scores_svc.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        elif k == 'neigh':\n",
    "            for i in range(len(v)):\n",
    "                final_scores_neigh[X.columns[i]] = (v[i] - base_score[k])\n",
    "            final_scores_neigh = sorted(final_scores_neigh.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "    print('Based on NB: ', final_scores_gnb)\n",
    "    print('Based on SVC : ', final_scores_svc)\n",
    "    print('Based on KNN: ', final_scores_neigh)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unusable_features(df, label_type):\n",
    "    if label_type == 'pvalue.label':\n",
    "        df = df.drop(['P.value.R', 'Direction.R', 'O.within.CI.R', 'Meta.analysis.significant'], axis=1)\n",
    "    elif label_type == 'O.within.CI.R':\n",
    "        df = df.drop(['P.value.R', 'Direction.R', 'Meta.analysis.significant', 'pvalue.label'], axis=1)\n",
    "    elif label_type == 'Meta.analysis.significant':\n",
    "        df = df.drop(['P.value.R', 'Direction.R', 'O.within.CI.R', 'pvalue.label'], axis=1)\n",
    "\n",
    "    cols_drop = set(['DOI', '1st.author.O', 'Senior.author.O', 'Authors.O', 'Study.Title.O', 'Unnamed: 0', 'new_feature_301', 'Unnamed: 0.1'])\n",
    "    cols_total = set(df.columns)\n",
    "    df = df.drop(cols_drop.intersection(cols_total), axis=1)\n",
    "    # df = df.replace(to_replace=np.nan, value=0)\n",
    "    df = df.dropna()\n",
    "    print('Shape is: ', df.shape)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(df, label_type):\n",
    "    total_true = total_false = total_val = 0\n",
    "    for i, row in df.iterrows():\n",
    "        total_val += 1\n",
    "        if row[label_type] == 1:\n",
    "            total_true += 1\n",
    "        else:\n",
    "            total_false += 1\n",
    "    print(\"Total rows is= \", total_val)\n",
    "    print(\"total_true % is= \", (total_true / total_val) * 100)\n",
    "    print(\"total_false % is=\", (total_false / total_val) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features_chi2(df, label_type):\n",
    "    df = remove_unusable_features(df, label_type)\n",
    "    X = df.drop([label_type], axis=1)\n",
    "    cols = X.columns\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    y = df[label_type]\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "    fit = bestfeatures.fit(X, y)\n",
    "    dfscores = pandas.DataFrame(fit.scores_)\n",
    "    dfcolumns = pandas.DataFrame(cols)\n",
    "    featureScores = pandas.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Specs', 'Score']\n",
    "    final_features = featureScores.nlargest(featureScores.shape[0] - 2, 'Score')\n",
    "    pandas.set_option('display.max_rows', final_features.shape[0] + 1)\n",
    "    return final_features, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(df, label_type, label_dict):\n",
    "    print('------------------------', 'Socre for: ', label_type, '------------------------')\n",
    "    df = remove_unusable_features(df, label_type)\n",
    "    get_baseline(df, label_type)\n",
    "    # X = df.drop([label_type], axis=1)\n",
    "    X = df[['new_feature_63', 'new_feature_93', 'new_feature_78', 'new_feature_139', 'new_feature_1',\n",
    "                     'new_feature_75', 'new_feature_292', 'new_feature_42', 'new_feature_111', 'new_feature_183']]\n",
    "        \n",
    "    y = df[label_type]\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    gnb = GaussianNB()\n",
    "    svc = SVC(kernel='rbf', gamma=0.9, C=1, random_state=0)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=5, p=2, weights='uniform')\n",
    "    forest = ensemble.RandomForestClassifier(random_state=0, n_estimators=10, max_features='auto', max_depth=10,\n",
    "                                             min_samples_split=2, min_samples_leaf=1, bootstrap=True)\n",
    "\n",
    "    xgboost = xgb.XGBClassifier(max_depth=7, objective='binary:logistic', learning_rate=1, colsample_bytree=1, reg_alpha=5,\n",
    "                                booster='gbtree', random_state=0)\n",
    "    gnb_score = np.mean(cross_val_score(gnb, X, y, cv=skf, n_jobs=1))\n",
    "    svc_score = np.mean(cross_val_score(svc, X, y, cv=skf, n_jobs=1))\n",
    "    neigh_score = np.mean(cross_val_score(neigh, X, y, cv=skf, n_jobs=1))\n",
    "    forest_score = np.mean(cross_val_score(forest, X, y, cv=skf, n_jobs=1))\n",
    "    xgboost_score = np.mean(cross_val_score(xgboost, X, y, cv=skf, n_jobs=1))\n",
    "    print(\"Cross Validation Score of NB is: %.2f\" % gnb_score)\n",
    "    print(\"Cross Validation Score of SVC is: %.2f\" % svc_score)\n",
    "    print(\"Cross Validation Score of KNN is: %.2f\" % neigh_score)\n",
    "    print(\"Cross Validation Score of Random Forest is: %.2f\" % forest_score)\n",
    "    print(\"Cross Validation Score of XGB is: %.2f\" % xgboost_score)\n",
    "\n",
    "    acc_arr = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(16, input_dim=X.shape[1], activation='sigmoid'),\n",
    "            keras.layers.Dense(8, activation='sigmoid'),\n",
    "            keras.layers.Dense(16, activation='sigmoid'),\n",
    "            keras.layers.Dense(8, activation='sigmoid'),\n",
    "            keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "        _, accuracy = model.evaluate(X_test, y_test)\n",
    "        acc_arr.append(accuracy)\n",
    "    print('Accuracy of this neural network model is: %.2f' % np.mean(acc_arr))\n",
    "    print(acc_arr, '\\n\\n')\n",
    "    label_dict['Naive_Bayes'].append(gnb_score)\n",
    "    label_dict['SVC'].append(svc_score)\n",
    "    label_dict['KNN'].append(neigh_score)\n",
    "    label_dict['Random_Forest'].append(forest_score)\n",
    "    label_dict['XGBoost'].append(xgboost_score)\n",
    "    label_dict['Neural_Network'].append(np.mean(acc_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_graph(df, label_type, cols, clf):\n",
    "    i = 10\n",
    "    sctr_plot = dict()\n",
    "    y = df[label_type]\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    while i < cols.shape[0]:\n",
    "        lst = cols['Specs'].head(i)\n",
    "        X = df[lst]\n",
    "        sctr_plot[i] = np.mean(cross_val_score(clf, X, y, cv=skf, n_jobs=1))\n",
    "        i += 1\n",
    "    x = sctr_plot.keys()\n",
    "    y = sctr_plot.values()\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(label_type + '_' + str(clf).split('(')[0])\n",
    "    plt.xlabel(\"Number of Features\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = ['pvalue.label', 'O.within.CI.R', 'Meta.analysis.significant']\n",
    "fileName='data/final_network_data.xlsx'\n",
    "df = pandas.read_excel(fileName, encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is:  (60, 319)\n",
      "Total rows is=  60\n",
      "total_true % is=  41.66666666666667\n",
      "total_false % is= 58.333333333333336\n",
      "------------------------ Socre for:  pvalue.label ------------------------\n",
      "Cross Validation Score of NB is: 0.75\n",
      "Cross Validation Score of SVC is: 0.80\n",
      "Cross Validation Score of KNN is: 0.72\n",
      "Cross Validation Score of Random Forest is: 0.78\n",
      "Cross Validation Score of XGB is: 0.77\n",
      "6/6 [==============================] - 0s 38ms/sample - loss: 0.5908 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 31ms/sample - loss: 0.5803 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 32ms/sample - loss: 0.6273 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 32ms/sample - loss: 0.6177 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 31ms/sample - loss: 0.4683 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 32ms/sample - loss: 0.5023 - accuracy: 1.0000\n",
      "6/6 [==============================] - 0s 32ms/sample - loss: 0.6079 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 68ms/sample - loss: 0.5448 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 32ms/sample - loss: 0.6291 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 36ms/sample - loss: 0.4481 - accuracy: 1.0000\n",
      "Accuracy of this neural network model is: 0.78\n",
      "[0.6666667, 0.8333333, 0.6666667, 0.8333333, 0.8333333, 1.0, 0.6666667, 0.6666667, 0.6666667, 1.0] \n",
      "\n",
      "\n",
      "Shape is:  (60, 319)\n",
      "------------------------ Socre for:  O.within.CI.R ------------------------\n",
      "Cross Validation Score of NB is: 0.75\n",
      "Cross Validation Score of SVC is: 0.75\n",
      "Cross Validation Score of KNN is: 0.70\n",
      "Cross Validation Score of Random Forest is: 0.68\n",
      "Cross Validation Score of XGB is: 0.63\n",
      "6/6 [==============================] - 0s 40ms/sample - loss: 0.6632 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 63ms/sample - loss: 0.5867 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 36ms/sample - loss: 0.6750 - accuracy: 0.3333\n",
      "6/6 [==============================] - 0s 58ms/sample - loss: 0.6928 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 39ms/sample - loss: 0.5852 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 33ms/sample - loss: 0.5330 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 48ms/sample - loss: 0.6469 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 37ms/sample - loss: 0.6015 - accuracy: 1.0000\n",
      "6/6 [==============================] - 0s 38ms/sample - loss: 0.5941 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 32ms/sample - loss: 0.6448 - accuracy: 0.6667\n",
      "Accuracy of this neural network model is: 0.73\n",
      "[0.6666667, 0.8333333, 0.33333334, 0.6666667, 0.8333333, 0.8333333, 0.6666667, 1.0, 0.8333333, 0.6666667] \n",
      "\n",
      "\n",
      "Shape is:  (60, 319)\n",
      "------------------------ Socre for:  Meta.analysis.significant ------------------------\n",
      "Cross Validation Score of NB is: 0.82\n",
      "Cross Validation Score of SVC is: 0.77\n",
      "Cross Validation Score of KNN is: 0.67\n",
      "Cross Validation Score of Random Forest is: 0.78\n",
      "Cross Validation Score of XGB is: 0.77\n",
      "6/6 [==============================] - 0s 32ms/sample - loss: 0.4497 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 31ms/sample - loss: 0.4671 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 31ms/sample - loss: 0.4605 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 32ms/sample - loss: 0.4612 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 35ms/sample - loss: 0.4495 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 36ms/sample - loss: 0.4719 - accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 36ms/sample - loss: 0.6462 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 36ms/sample - loss: 0.6744 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 44ms/sample - loss: 0.6641 - accuracy: 0.6667\n",
      "6/6 [==============================] - 0s 34ms/sample - loss: 0.6500 - accuracy: 0.6667\n",
      "Accuracy of this neural network model is: 0.77\n",
      "[0.8333333, 0.8333333, 0.8333333, 0.8333333, 0.8333333, 0.8333333, 0.6666667, 0.6666667, 0.6666667, 0.6666667] \n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {'Naive_Bayes': [0.7500000000000001, 0.75, 0.8166666666666667], 'SVC': [0.8, 0.75, 0.7666666666666668], 'KNN': [0.7166666666666667, 0.7000000000000001, 0.6666666666666666], 'Random_Forest': [0.7833333333333332, 0.6833333333333333, 0.7833333333333334], 'XGBoost': [0.7666666666666668, 0.6333333333333334, 0.7666666666666668], 'Neural_Network': [0.7833333, 0.73333335, 0.7666666]})\n"
     ]
    }
   ],
   "source": [
    "label_dict = defaultdict(list)\n",
    "for label in all_labels:\n",
    "    modelling(df, label, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated values of all the models are:\n",
      "Naive_Bayes : 0.77\n",
      "SVC : 0.77\n",
      "KNN : 0.69\n",
      "Random_Forest : 0.75\n",
      "XGBoost : 0.72\n",
      "Neural_Network : 0.76\n"
     ]
    }
   ],
   "source": [
    "print('Aggregated values of all the models are:')\n",
    "for k, v in label_dict.items():\n",
    "    label_dict[k] = np.mean(v)\n",
    "    print(k, ': %.2f'% label_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various Tests\n",
    "# print(features)\n",
    "# ablation_test(df, label_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in all_labels:\n",
    "#     gnb = GaussianNB()\n",
    "#     svc = SVC(kernel='rbf', gamma=0.9, C=1, random_state=0)\n",
    "#     neigh = KNeighborsClassifier(n_neighbors=5, p=2, weights='uniform')\n",
    "#     forest = ensemble.RandomForestClassifier(random_state=0, n_estimators=10, max_features='auto', max_depth=10,\n",
    "#                                              min_samples_split=2, min_samples_leaf=1, bootstrap=True)\n",
    "\n",
    "#     xgboost = xgb.XGBClassifier(max_depth=7, objective='binary:logistic', learning_rate=1, colsample_bytree=1, reg_alpha=5,\n",
    "#                                 booster='gbtree')\n",
    "#     for j in [gnb, svc, neigh, forest, xgboost]:\n",
    "#         features, df = select_best_features_chi2(df, i)\n",
    "#         plot_feature_graph(df, i, features, j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
